---
title: "Project Checkpoint"
author: "Vicky Wang"
date: "November 5th, 2021"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    theme: lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Project Checkpoint

This project checkpoint is designed for you to begin your data exploration process. Before creating a multiple linear regression model, you should always familiarize yourself with the data set and its individual variables. In this checkpoint, you will create numerical summaries and visualizations that should help guide your modelling process -- which explanatory variables will help explain the outcome, which variables need any transformation, which variables may need an interaction, etc. 

Most of your data sets have *several* predictors to choose from. In this assignment, I only ask that you analyze a few of them, but **please do not limit yourself to these variables** throughout your final project. Creating your regression model should be an iterative process that uses different analysis techniques to create the best fitting model possible - trying out new variables, examining different transformations, etc.  

You all selected a few *potential* explanatory variables of interest in your project proposal. **These do not have to be the variables used here.** You may find that they're not as helpful in explaining the response as you thought. You are welcome (and encouraged!) to change, adjust, and [pivot](https://www.youtube.com/watch?v=8w3wmQAMoxQ), as needed. 

And if you have any questions throughout the process, please ask us! The instructional team is here to help!



### Creating an RStudio Project

Now is a good time to create an RStudio Project (like you did in Lab 6) to keep all of your project documents in one place. To do this, please follow these steps:

1. Open up a *new* session of RStudio
2. Navigate to File > New Project
3. Click on New Directory
4. Click on New Project
5. Give your project a "Directory name" (something like "stats401project")
6. Decide where you would like the project stored (I keep mine - and all other Stats 401 assignments - in a folder on my computer called stats401)
7. Click "Create Project" 
8. Move this "projectCheckpoint.Rmd" document and your data set to the project folder 



### Read Data

Once you have created your RStudio Project and moved your data set into the folder, you will then be able to read in your data. To do this, you'll use the `read.csv()` function and store it for use throughout the file.

Reach out to us if you need help reading in your data!

```{r readData}
# Replace this text with your code
fires <- read.csv("forestfires.csv")
head(fires)
fires$month <- as.factor(fires$month)
str(fires)
fires$month <- factor(fires$month, levels = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"))
```

```{r cleaningupbecausethisisanewdataset}
fires <- na.omit(fires)
head(fires)
```
```{r morefixy}
fires <- fires[, c(3,5,9,11,12)]
head(fires)
```
Once you have successfully loaded your data, complete the tasks below to complete the project checkpoint. *Failure to properly follow the instructions will result in point deductions.*



### Variables (2 points)

Fill in the following bullets with the variables you will be analyzing below. I recommend starting with the variables you described in your project proposal, but these can change throughout your modelling process. There is no specific number of variables that your final model has to contain. 

- Response: area
- Quantitative Predictor #1: FFMC
- Quantitative Predictor #2: temp
- Quantitative Predictor #3: wind
- Categorical Predictor: month



### Numerical Summaries (4 points)

Run the numerical summaries (using `summary()` or other similar functions) for your quantitative variables (response + predictors).

```{r numericalSummaries}
# Replace this text with your code
summary(fires$area)
summary(fires$FFMC)
summary(fires$temp)
summary(fires$wind)
```

What is the mean and range of your *response* variable? This is the variability that you will be trying to explain with your model!

**Answer:** Mean of Area:  18.141 ha
Range: 746.28 - 0.170 = 746.11 ha



### Histograms (10 points)

Create four histograms for your quantitative variables (response + predictors). *Be sure to give each plot appropriate axis labels and a title.* 

```{r histograms}
# Replace this text with your code
hist(fires$area,
     xlab = "Area Burned (in ha)",
     main = "Histogram of Burned Forest Area in Montesinho Park",
     col = "purple",
     breaks = 50)

hist(log(fires$area),
     xlab = "log(Area Burned)",
     main = "Histogram of Log(Burn Area) in Montesinho Park",
     col = "green")

hist(fires$FFMC,
     xlab = "Fine Fuel Moisture Code",
     main = "Histogram of FFMC Index Values",
     col = "pink",
     breaks = 20)

hist(fires$temp,
     xlab = "Temperature (C)",
     main = "Histogram of Temperatures During Burns",
     col = "red",
     breaks = 20)

hist(fires$wind,
     xlab = "Wind Speed (km/h)",
     main = "Histogram of Wind Speeds During Burns",
     col = "hotpink")
```

In 2 - 3 sentences, reflect on your histograms. Things to consider: Would any of these quantitative variables benefit from a log transformation? Remember, we are looking for a *heavy* right skew - not just a slight right skew. (I recommend plotting the log-transformed variable to verify that the transformation helps.)

**Answer:** My quantative variables all show unique distributions when relating to times when forest fires were occurring and how conditions impacted its intensity. The variable "area" shows a significant right skew and therefore would benefit from a log transformation, which I included above (in green!). FFMC, on the other hand, shows a left skew, so the log transformation would not help. Finally, temperature and wind speed are generally fairly normal in their distribution and can therefore remain as is.



### Scatterplot Matrix (6 points)

Create a **scatterplot matrix** of your response against the three quantitative predictors. Note: we are not asking for individual scatterplots.

```{r scatterplotMatrix}
# Replace this text with your code
plot( ~ FFMC + temp + wind + area, data = fires)
```

In 2 - 3 sentences, reflect on your scatterplot matrix. Things to consider: Do there appear to be any significant linear relationships between any of the predictors and your response variable? Would any of the predictors potentially benefit from adding a quadratic term? Are there any strong relationships between two of the predictor variables?

**Answer:** The scatterplots don't look the absolute best due to clusters of points in many of the plotted relationships. None of the scatterplots look very linear in nature either. For the relationships that show clusters of points, I would want to look further into whether any categorical variables are causing groupings of data. No two of the predictor variables show a very strong relationship.

**Also: I graphed it again below with the omitted outlier and most relationships still look fairly random and lacking in a significant linear relationship.**

### Boxplot (6 points)

Create a side-by-side boxplot of your response variable versus your categorical predictor. *Be sure to give your plot appropriate axis labels and a title.* 

```{r sideBySideBoxplot}
plot(area ~ month, data = fires,
     xlab = "Month",
     ylab = "Burn Area Size",
     main = "Burn Area vs Month of Burn for Forest Fires",
     col = c("red", "orange", "yellow", "green", "chartreuse", "blue", "purple", "deeppink", "hotpink", "pink", "grey", "black"))

legend("topright",
       legend = levels(fires$month),
       col = c("red", "orange", "yellow", "green", "chartreuse", "blue", "purple", "deeppink", "hotpink", "pink", "grey", "black"),
       pch = 1,
       cex = 0.50)
```
In 1 - 2 sentences, reflect on your boxplot. Things to consider: Are there differences in the response between the various groups? Do you think that including the categorical variable would improve your model? (If yes, you may want to create a scatterplot *by groups* in the future!)

**Answer:** The boxplots are pretty hard to analyze the way they are currently. Because of that massive outlier in April (~750 ha), the scale for burn area is on a pretty large scale. As a result, it is a bit difficult to tell what differences there are in the response between the months that the fires happened. However, it looks like the some of the months show generally higher burn sizes than others, although many groups show outliers that extend even higher in number. For example, May looks to have significantly higher burn area than many of the months, while April shows a larger range of burn areas. These are all important to consider because it shows that the month may have an impact on the total burn size of a forest fire.

**To address this outlier, I decided to create a new file that omitted that enormous outlier so I could better look at the more important fires that fit better into the general model. The -c(n) function refused to delete the row I wanted, so I made a new .csv file that I will now read in then create a graph with.**

```{r new file}
omitted <- read.csv("forestfires_omit_417.csv")
```

```{r deleteemptyrows}
omitted <- na.omit(omitted)
omitted$month <- as.factor(omitted$month)
```

```{r newscattermatrix}
plot( ~ FFMC + temp + wind + area, data = omitted)
```
```{r new sidebyside}
plot(area ~ month, data = omitted,
     xlab = "Month",
     ylab = "Burn Area Size",
     main = "Burn Area vs Month of Burn for Forest Fires",
     col = c("red", "orange", "yellow", "green", "chartreuse", "blue", "purple", "deeppink", "hotpink", "pink", "grey", "black"))

legend(x = 8, y = 270,
       legend = levels(omitted$month),
       col = c("red", "orange", "yellow", "green", "chartreuse", "blue", "purple", "deeppink", "hotpink", "pink", "grey", "black"),
       pch = 1,
       cex = 0.50)
```

After deleting that 700+ outlier, this lets me look at the general trend of the data better. This clearly shows at least one of the months shows a different average burn area when compared to a number of the other months. Therefore, this categorical model would probably improve my model.

### Conclusions (4 points)

Write 3 - 5 sentences summarizing your initial findings. Highlight any key findings from the above initial data exploration and where you plan to go from here. If you have any questions for the instructional team (about coding, the direction of your analysis, possible transformations, etc.), you can include them here! This doesn't have to be anything new/profound from what you discovered above. 

**Answer:** It looks like the three quantitative variables I picked as predictors may or may not show a relationship with not only each other, but the response variable "area" as well. There is a concerning lack of pattern among any two predictors in the scatterplot matrix, which leads me to believe that I need to examine whether inclusion of interaction terms or additional variables will show a better relationship, since currently no one of the predictors is super predictive. The categorical variable I used does seem to have an impact on the burn area, so pairing this term with one of the quantitative variables may be beneficial. To continue with analysis, I will be using the second data set I created that took out the biggest outlier from the data set because it allows me to focus on the non-anomalous points better. Looking forward, I will focus closely on adding variables into my model and determining the best fit possible, while being mindful of overparameterization, overfitting, and multicollinearity.






